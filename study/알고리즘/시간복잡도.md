
## 시간복잡도 
- 어떤 알고즘을 수행하는데 걸리는 시간을 설명하는 계산 복잡도를 의미한다. 일반적으로 알고리즘의 성능 분석은 실행에 필요한 공간 측면에서 분석하는 **공간 복잡도**,실행 소요시간 측면에서 분석하는 **시간 복잡도**를 추정하여 평가를 한다.
- 알고리즘의 실행 시간을 두 부분으로 나누면 다음과 같다.
    - 입력값의 크기에 따른 알고리즘의 실행시간
    - 입력값의 크기에 따른 함수의 증가량,즉 성장률(rate of growth)을 의미한다. 이 때 중요하지 않은 부분을 제거하면 알고리즘의 실행 시간에서 중요한 부분인 성장률에 집중할 수 있다. 이렇게 제거한 것을 점근적 표기법(asymptotic notation)이라 한다.
- 계산 복잡도를 표기하는 대표적인 방법이 바로 Big-O(빅오)다.

## 빅오 표기법(Big-O)

- 알고리즘 성능을 수학적으로 표기해주는 표기법으로 알고리즘의 실행시간보다는 데이터나 사용자 증가률에 따른 알고리즘 성능을 예측하는게 목표이므로 중요하지 않은 부분인 상수와 같은 숫자는 모두 제거한다.
- 즉, 빅오 표기법은 불필요한 연산을 제거하여 알고리즘 분석을 쉽게 할 목적으로 사용된다.
- 측정되는 복잡성에는 시간 복잡도와 공간 복잡도가 있다.
    - 시간 복잡도 : 입력되는 n의 크기에 따라 실행되는 조작의 수
    - 공간 복잡도 : 알고리즘이 실행될 때 사용하는 메모리 양 (메모리 발전으로 중요도 낮아지는 중)

## 시간복잡도 
- 알고리즘을 수행하기위해 프로세스가 수행해야하는 연산을 수치화 한 것. 실행시간이 아닌 연산수치로 판별하는 이유는 명령어의 실행시간은 컴퓨터의 하드웨어 또는 프로그래밍 언어에 따라 편차가 크게 달라지기때문에 **명령어의 실행 횟수만을** 고려하는 것.
- 시간 복잡도에서 중요하게 보는 것은 가장 큰 영향을 미치는 N의 단위이다.
```
1          O(1)   -> 상수
2n + 20 -> O(n)   -> n이 가장 큰 영향을 미친다.
3n^2       O(n^2) -> n^2이 가장 큰 영향을 미친다.

```

- 시간복잡도의 문제해결 단계를 나열하면 아래와 같다.
```
O(1)     상수시간    : 문제를 해결하는데 오직 한 단계만 처리함.
O(log n) 로그시간    : 문제를 해결하는데 필요한 단계들이 연산마다 특정 요인에 의해 줄어듬. 
O(n)     직선적 시간 : 문제를 해결하기위한 단계의 수와 입력값이 1:1 관계를 가짐.
O(n log n)        : 문제를 해결하기위한 단계의 수가 N*(log2N) 번만큼의 수행시간을 가진다.(선형로그형) 
O(n^2)   2차 시간   : 문제를 해결하기위한 단계의 수는 입력값 n의 제곱.
O(C^n)   지수 시간   : 문제를 해결하기위한 단계의 수는 주어진 상수값 C의 n 제곱.
```

- 시간복잡도 단계 (빠른순)
```
[fast]O(1) < O(log n) < O(n) < O(n log n) < O(n^2)
```


### O(1) 상수
```
def hellow_world():
    print("hello, world!)
```
```
def O_1_algorithm(arr, index):
    return arr[index]

arr = [1, 2, 3, 4, 5]
index = 1
result = O_1_algorithm(arr, index)
print(result)  # 2
```
- 입력에 관계없이 복잡도는 동일하게 유지된다.
-  즉, 입력값이 증가하더라도 시간이 늘어나지않는다. 입력값의 크게와 관계없이 즉시 출력값을 얻어낼수 있다.

![image](https://github.com/user-attachments/assets/27578b5f-4f60-4ad1-9f69-781074083887)

### O(N) 선형
```
def print_each(li):
    for item in li:
        print(item)
```

```
import time

def O_n_algorithm(n):
    for i in range(n):
        # do something for 1 second
        time.sleep(1)  # 예시로 1초 동안 쉬게 함

def another_O_n_algorithm(n):
    for i in range(2 * n):
        # do something for 1 second
        time.sleep(1)  # 예시로 1초 동안 쉬게 함


# 실행 예시
O_n_algorithm(3)          # 총 3초 걸림
another_O_n_algorithm(3)  # 총 6초 걸림
```

![image](https://github.com/user-attachments/assets/79b87555-2708-4a89-bc52-da99575a44fc)

- 입력이 증가하면 처리 시간 또는 메모리 사용이 선형적으로 증가한다. 
- 즉, 입력값이 증가함에 따라 수행 시간도 같은 비율로 증가한다. 
- 예를 들어 입력값이 1일때 1초의 시간이 걸리고 입력값이 100일때 100초가 걸리는 알고리즘이 있다면 그 알고리즘은 O(n)의 시간복잡도를 가진다. 

### O(log n) : logarithmic complexity

![image](https://github.com/user-attachments/assets/38ad0f94-1cdc-46d4-86f1-b211652c779c)

- O(1) 다음으로 빠른 시간복잡도를 가진다.
- 주로 입력크기에 따라 처리시간이 증가하는 정렬 알고리즘에서 많이 사용된다. 
- 이진검색의 탐색도 같은 로직으로 O(log n)의 시간 복잡도를 가진 알고리즘이다.다음은 이진검색의 예다. 
```
def binary_search(li, item, first=0, last=None):
    if not last: 
        last = len(li)
    midpoint = (last - first) / 2 + first

    if li[midpoint] == item:
        return midpoint
    
    elif li[midpoint] > itme:
        return binary_search(li, item, first, midpoint)
    
    else:
        return binary_search(li, item, midpoint, last)

```

- 이진검색에 원하는 값을 탐색할 때, 노드를 이동할 때마다 경우의 수가 절반으로 줄어든다. 이해하기 쉬운 게임으로 비유해 보자면 up & down을 예로 들 수 있다.
    - 1~100 중 하나의 숫자를 플레이어1이 고른다 (30을 골랐다고 가정).
    - 50(가운데) 숫자를 제시하면 50보다 작으므로 down을 외친다.
    - 1~50중의 하나의 숫자이므로 또다시 경우의 수를 절반으로 줄이기 위해 25를 제시한다.
    - 25보다 크므로 up을 외친다.
    - 경우의 수를 계속 절반으로 줄여나가며 정답을 찾는다.
    - 매번 숫자를 제시할 때마다 경우의 수가 절반이 줄어들기 때문에 최악의 경우에도 7번이면 원하는 숫자를 찾아낼 수 있게 된다.

- 여기서 log는 알고리즘 세계에서 데이터를 계속해서 반으로 나눈다는 뜻으로 이 데이터를 1이 될 때까지 반(2)으로 몇 번 쪼갤 수 있는가?라고 보면된다. 예를 들어 N이 10만개라고 할때 반으로 계속 쪼개면 약 17번에 1이 된다. 
    - 고로 log N 시간 복잡도를 계산할때 log 값은 데이터 개수 X 쪼갠 횟수로 계산하면 된다. N이 100,000 라면 100,000 X 17 = 1,700,000 170만번이다. 컴퓨터가 1초 동안 처리할 수 있는 연산 횟수의 기준을 보통 1억번으로 잡는데 코테는 시간 제한을 보통 1초 ~ 2초준다. 그럼 100,000,000번(1억 번)은 1초이고 1,700,000번(170만 번) 은 약 0.002초라고 볼 수 있음으로 통과다.

- 밑의 표를 외우면 편하다. 
![image](https://github.com/user-attachments/assets/12583502-f1d0-4f66-a61a-9a6dba70b268)


### O(n2) : quadratic complexity

![image](https://github.com/user-attachments/assets/f9cff9c6-2618-4991-a0e9-b2319b1f9fec)

- 입력값이 증가함에 따라 시간이 n의 제곱수의 비율로 증가하는 시간 복잡도다. 
- 예를 들어 입력값이 1일 경우 1초가 걸리던 알고리즘에 5라는 값을 주었더니 25초가 걸리게 된다면, 이 알고리즘의 시간 복잡도는 O(n2)라고 표현한다.
- 2n, 5n을 모두 O(n)이라고 표현하는 것처럼, n3과 n5도 모두 O(n2)로 표기한다. n이 커지면 커질수록 지수가 주는 영향력이 점점 퇴색되기 때문에 이렇게 표기한다.

```

def O_quadratic_algorithm(n):
    for i in range(n):
        for j in range(n):
            # do something for 1 second
            time.sleep(1)  # 예시로 1초 동안 쉬게 함

def another_O_quadratic_algorithm(n):
    for i in range(n):
        for j in range(n):
            for k in range(n):
                # do something for 1 second
                time.sleep(1)  # 예시로 1초 동안 쉬게 함


# 실행 예시
# O_quadratic_algorithm(2) → 총 4초 (2*2번 실행)
# another_O_quadratic_algorithm(2) → 총 8초 (2*2*2번 실행)

```

### O(2n) : exponential complexity

![image](https://github.com/user-attachments/assets/91044f49-4da5-42ca-a04d-82feef245f66)


- Big-O 표기법 중 느린 시간 복잡도를 가진다.구현한 알고리즘의 시간 복잡도가 O(2n)이라면 다른 접근 방식을 고민해 보는 것이 좋다.
- 종이를 42번 접으면 그 두께가 지구에서 달까지의 거리보다 커진다는 말이 있다. 고작 42번 만에 얇은 종이가 그만한 두께를 가질 수 있는 것은, 매번 접힐 때마다 두께가 2배로 늘어나기 때문이다.
- 아래는 재귀로 구현하는 피보나치 수열로 O(2n)의 시간 복잡도를 가진 대표적인 알고리즘이다.

```
def fibonacci(n):
    if n <= 1:
        return 1
    return fibonacci(n - 1) + fibonacci(n - 2)


# 실행 예시
print(fibonacci(5))  # 8
```

## 시간복잡도 계산하기
- 문제를 보거나 풀이를 보고 시간 복잡도를 계산 할 줄 알아야 어떻게 풀어야하는 지 감을 잡을 수 있다. 
- 코딩 테스트에서 시간 초과를 판단하려면, 대략 몇번의 연산이 1초에 가능한가를 알야아한다. 
    - 연산 횟수 = 시간복잡도 x 데이터의 크기 다.
- 시간 복잡도를 계산할때는 아래의 순서로 진행하면 좋다.
    - 중첩이면 곱하고 순차면 더한다. 중첩된 루프부터 분석한다. ex) 이중 for문은 O(n^2)이다.
    - 주요 연산에 해당하는 조건문, 배열 접근, 함수 호출 등 실행에 걸리는 시간을 체크한다.
    - 상수항을 제거한다. ex) O(2n + 3)은 O(n)으로 간주한다. 증가율이 중요하기때문이다.
    - 가장 높은 차수만 남긴다. 예를 들어 O(n^2 + n)은 O(n^2)으로 표기한다.

### 시간 복잡도 계산 예시  
- for i in N: → for j in N:	
    - 이중 for문은 중첩되어있음으로 곱한다. O(N × N) = O(N²) 
    - 입력이 10배 늘면, 실행 횟수는 100배 는다. 만약 N = 100,000라면 10,000,000,000개의 연산이 필요하다. 
- for i in N: + for j in N:	
    - 두 루프가 순차적으로 실행됨으로 더한다.
    - N + N = 2N → O(N) 시간복잡도 계산시 상수는 버리므로 O(2N) = O(N)
    -  O(N + N) = O(N)
- for in N: + if x in set:
    - 반복 안의 연산이 O(1)임으로 곱하면 O(N × 1) = O(N)	
  
### 입력값으로 필요 시간 복잡도 유추하기 
- 일반적으로 코딩 테스트 환경에서는 1초당 컴퓨터가 처리할 수 있는 연산 횟수를 대략 10^8(1억번)으로 가정한다. 다만 이는 언어따라 처리 속도가 다르므로(1초에 10⁸번은 C/C++ 기준) Python의 경우 약 10⁶ ~ 5×10⁶(100만 ~ 500만번) 수준으로 생각하는게 좋다. 
    - 이는 최대치임으로 보수적으로 1초당 1000만 ~ 3000만 번의 연산 횟수를 목표치로 권장하는 것이 좋다. 
- 자바는 JVM 위에서 돌아가고, Scanner 대신 BufferedReader를 쓰는 등의 입출력 방식에 따라 속도 차이가 큽니다. 따라서 1초당 5,000만 번 정도로 보수적으로 잡는 것이 안전하다.
    - 코테의 경우 주어진 N의 갯수로 풀이의 시간복잡도를 추측해야한다. 언어에 따라 다르지만 자바의 경우 보통 보수적으로 1초에 5000만번 ~1억번이 가능하다고 본다. 
    - N이 2,000개인 경우 : 2,000 X 2,000 = 400만 번 -> 이건 이중 반복문 O(N^2) 써도 1억 번 안 넘기때문에 이중반복문을 써도 됨. 만약
    - N이 5,000인 경우 : 5,000 X 5,000 = 2,500만번임으로 1억보다 작아서 괜찮아보이지만 반복문 안의 코드가 복잡하면 자바에서는 1초를 넘길 수 있다. 이런 경우 가급적 O(N log N)의 풀이를 고민해보는 게 좋다.
    - N이 10만~20만개인 경우 :  이중 반복문 쓰면 100억~400억 번이 됨으로 N log N(10만 X 17) 안으로 풀어야 한다.
    - N이 1,000만개인 경우 :  10,000,000 X 24(log)의 경우 2억 4천만번이다. N log N도 시간 초과 될 수 있음으로 O(N) 시간복잡도(ex 한번의 반복문)으로 풀어야 함.

![image](https://github.com/user-attachments/assets/0265fd03-2edf-4c1b-b7be-43d1c6cc6f10)

- 만약 제한시간이 2초라면 연산횟수를 2억번까지 생각해도 되지만 연습시에는 항상 최악의 상황을 가정하여 1초에 맞춰서 풀이하는 방법을 구현해보는 것이 좋다. 


- 시간 제한을 보고 허용 연산 횟수를 추정한다. 시간 X 10^8(1억번)
- 문제에 제시된 데이터의 크기 N의 최댓값을 확인한다. 최악의 경우를 가정하는 것이 좋음으로 계산의 기준은 N의 최댓값으로 잡는다.
- 계산된 총 연산횟수가 허용 연산횟수보다 작거나 같아야 문제가 없는 풀이라고 볼 수 있다. 
- 필요한 시간복잡도를 계산하기위해선 알고리즘 별 시간 복잡도를 외우고 데이터 크기를 보고 어떤 시간복잡도 내에 풀어야하는 지 추론 -> 추론한 시간복잡도에 맞는 알고리즘을 선택 할 수 있어야한다. 

![image](https://github.com/user-attachments/assets/b5f0b177-500a-41ab-afda-a107c8278325)



## 공간 복잡도(Space Complexity)
- 공간 복잡도는 알고리즘이 수행되는 데에 필요한 메모리의 총량을 의미한다. 즉, 프로그램이 필요로 하는 메모리 공간을 산출하는 것을 의미한다. 프로그램이 요구하는 공간은 고정적인 공간과 함께 가변적인 공간을 함께 요구한다. 
- 고정적인 공간은 처리할 데이터의 양에 무관하게 항상 요구되는 공간으로, 프로그램의 성능에 큰 영향을 주지않지만 가변적인 공간은 처리할 데이터의 양에 따라 다르게 요구되는 공간으로서 프로그램의 성능에 큰 영향을 준다.
- 이런 공간 복잡도 계산은 시간 복잡도 계산과 비슷하게 빅 오 (Big-O) 표기법으로 표현한다.
- 보통 때의 공간 복잡도는 시간 복잡도보다 중요성이 떨어진다. 시간이 적으면서 메모리까지 지수적으로 증가하는 경우는 거의 없으며 시간 내에 발생하는 메모리 문제들은 보통 알고리즘을 구현할 때 발생하는 문제이기 때문이다.
- 보통 시간 복잡도에 맞다면 공간 복잡도가 통과하는 경우가 많기때문에, 알고리즘 구현시 공간 복잡도에 실패했다면 변수를 설정할때 쓸데 없는 공간을 차지하도록 설정했을 경우가 많으니 확인이 필요하다. 
- 그러나 때에 따라 공간 복잡도를 중요하게 보는 경우가 있는데, 동적 계획법(Dynamic Programming)과 같은 알고리즘이나 하드웨어 환경이 매우 한정된 경우가 바로 그 경우다. 동적 계획법은 알고리즘 자체가 구현 시 메모리를 많이 요구하기 때문에 입력값의 범위가 넓어지면 사용하지 못하는 경우도 많고, 하드웨어 환경이 매우 한정되어 있는 경우(ex. 임베디드, 펌웨어 등)라면 가용 메모리가 제한되어 있기 때문이다.



#### 참고링크 
- https://ssdragon.tistory.com/100
- 파이썬 알고리즘 인터뷰(책)
- https://velog.io/@abc2752/%EC%8B%9C%EA%B0%84-%EB%B3%B5%EC%9E%A1%EB%8F%84Time-Complexity
- https://blog.chulgil.me/algorithm/
- https://best-coding.tistory.com/24#google_vignette
- https://blog.kevink1113.com/entry/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%8B%9C%EA%B0%84-%EB%B3%B5%EC%9E%A1%EB%8F%84-%EA%B3%84%EC%82%B0%ED%95%98%EA%B8%B0-%ED%9A%A8%EC%9C%A8%EC%84%B1%EC%9D%84-%EB%86%92%EC%9D%B4%EC%9E%90
- https://young0378.tistory.com/42